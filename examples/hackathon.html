<html lang="en">
	<head>
		<title>three.js - WebGPU - Compute</title>
		<meta charset="utf-8" />
		<meta
			name="viewport"
			content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0"
		/>
		<link type="text/css" rel="stylesheet" href="main.css" />
	</head>
	<body>
		<div id="info">
			<a href="https://threejs.org" target="_blank" rel="noopener">three.js</a>
			WebGPU - Compute
		</div>
		<h1>Hello Mehdi lets gooo!!!!</h1>
		<h2>Local Audio Visualizer Test Ve + Mehdi!!!!</h2>
		<div id="overlay">
			<button id="startButton">Play</button>
		</div>
		<div id="container"></div>

		<script
			async
			src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"
		></script>

		<script type="importmap">
			{
				"imports": {
					"three": "../build/three.module.js",
					"three/addons/": "./jsm/",
					"three/nodes": "./jsm/nodes/Nodes.js"
				}
			}
		</script>

		<script type="module">
			import * as THREE from "three";
			import {
				ShaderNode,
				uniform,
				storage,
				attribute,
				float,
				vec2,
				vec3,
				color,
				instanceIndex,
				PointsNodeMaterial,
				sampler2D,
			} from "three/nodes";

			import { GUI } from "three/addons/libs/lil-gui.module.min.js";

			import WebGPU from "three/addons/capabilities/WebGPU.js";
			import WebGPURenderer from "three/addons/renderers/webgpu/WebGPURenderer.js";

			let scene, camera, renderer, analyser, uniforms;
			let audioDataTexture;
			let computeNode;

			const startButton = document.getElementById("startButton");
			startButton.addEventListener("click", init);

			const pointerVector = new THREE.Vector2(-10.0, -10.0); // Out of bounds first
			const scaleVector = new THREE.Vector2(1, 1);

			function init() {
				if (WebGPU.isAvailable() === false) {
					document.body.appendChild(WebGPU.getErrorMessage());

					throw new Error("No WebGPU support");
				}

				// For Audio
				const fftSize = 128;

				const overlay = document.getElementById("overlay");
				overlay.remove();

				camera = new THREE.OrthographicCamera(-1.0, 1.0, 1.0, -1.0, 0, 1);
				camera.position.z = 1;

				scene = new THREE.Scene();

				// initialize particles

				const particleNum = 300000;
				const particleSize = 2; // vec2

				const particleArray = new Float32Array(particleNum * particleSize);
				const velocityArray = new Float32Array(particleNum * particleSize);

				// Set up AUDIO  context
				// const audioContext = new AudioContext();

				// // Create an audio source
				// const audioSource = new Audio(audioContext);

				// // const audio = new THREE.Audio( listener );
				// audioSource
				// 	.load(file)
				// 	.then(() => {
				// 		audioSource.play();
				// 	})
				// 	.catch((error) => {
				// 		console.error("Error loading audio:", error);
				// 	});

				// // Initialize the AudioAnalyser

				// analyser = new THREE.AudioAnalyser(audioContext, fftSize);

				const listener = new THREE.AudioListener();

				const audio = new THREE.Audio(listener);
				const file = "./sounds/376737_Skullbeatz___Bad_Cat_Maste.mp3";

				if (/(iPad|iPhone|iPod)/g.test(navigator.userAgent)) {
					const loader = new THREE.AudioLoader();
					loader.load(file, function (buffer) {
						audio.setBuffer(buffer);
						audio.play();
					});
				} else {
					const mediaElement = new Audio(file);
					mediaElement.play();

					audio.setMediaElementSource(mediaElement);
				}

				analyser = new THREE.AudioAnalyser(audio, fftSize);
				console.log("THREE AUDIO ANALYSER:");

				// create buffers

				const particleBuffer = new THREE.InstancedBufferAttribute(
					particleArray,
					2
				);
				const velocityBuffer = new THREE.InstancedBufferAttribute(
					velocityArray,
					2
				);

				const particleBufferNode = storage(particleBuffer, "vec2", particleNum);
				const velocityBufferNode = storage(velocityBuffer, "vec2", particleNum);

				// create function
				// computeShaderNode original
				// const computeShaderNode = new ShaderNode((stack) => {
				// 	const particle = particleBufferNode.element(instanceIndex);
				// 	const velocity = velocityBufferNode.element(instanceIndex);

				// 	const pointer = uniform(pointerVector);
				// 	const limit = uniform(scaleVector);

				// 	const position = particle.add(velocity);

				// 	stack.assign(
				// 		velocity.x,
				// 		position.x
				// 			.abs()
				// 			.greaterThanEqual(limit.x)
				// 			.cond(velocity.x.negate(), velocity.x)
				// 	);
				// 	stack.assign(
				// 		velocity.y,
				// 		position.y
				// 			.abs()
				// 			.greaterThanEqual(limit.y)
				// 			.cond(velocity.y.negate(), velocity.y)
				// 	);

				// 	stack.assign(position, position.min(limit).max(limit.negate()));

				// 	const pointerSize = 0.1;
				// 	const distanceFromPointer = pointer.sub(position).length();

				// 	stack.assign(
				// 		particle,
				// 		distanceFromPointer
				// 			.lessThanEqual(pointerSize)
				// 			.cond(vec3(), position)
				// 	);
				// });

				// computeShaderNode modified

				const computeShaderNode = new ShaderNode((stack) => {
					const particle = particleBufferNode.element(instanceIndex);
					const velocity = velocityBufferNode.element(instanceIndex);

					const pointer = uniform(pointerVector);
					const limit = uniform(scaleVector);

					const position = particle.add(velocity);

					// Get the audio data texture from analyser
					const audioDataTexture = uniform(new sampler2D());

					// Use the audio data to modify particle behavior
					const audioFrequency = audioDataTexture.sample(pointerVector).r; // Get audio data at the current pointer position

					// Modify particle behavior based on audio frequency
					// For example, you can adjust the velocity of particles based on audio frequency
					velocity.add(vec2(audioFrequency * 0.1)); // Modify the 0.1 factor to control the response strength

					stack.assign(
						velocity.x,
						position.x
							.abs()
							.greaterThanEqual(limit.x)
							.cond(velocity.x.negate(), velocity.x)
					);
					stack.assign(
						velocity.y,
						position.y
							.abs()
							.greaterThanEqual(limit.y)
							.cond(velocity.y.negate(), velocity.y)
					);

					stack.assign(position, position.min(limit).max(limit.negate()));

					const pointerSize = 0.1;
					const distanceFromPointer = pointer.sub(position).length();

					stack.assign(
						particle,
						distanceFromPointer
							.lessThanEqual(pointerSize)
							.cond(vec3(), position)
					);
				});

				// Set the audio data texture to the analyser data texture
				computeShaderNode.onBeforeCompile = (shader) => {
					shader.uniforms.audioDataTexture = audioDataTexture;
				};

				// compute original

				computeNode = computeShaderNode.compute(particleNum);

				computeNode.onInit = ({ renderer }) => {
					const precomputeShaderNode = new ShaderNode((stack) => {
						const particleIndex = float(instanceIndex);

						const randomAngle = particleIndex.mul(0.005).mul(Math.PI * 2);
						const randomSpeed = particleIndex.mul(0.00000001).add(0.0000001);

						const velX = randomAngle.sin().mul(randomSpeed);
						const velY = randomAngle.cos().mul(randomSpeed);

						const velocity = velocityBufferNode.element(instanceIndex);

						stack.assign(velocity.xy, vec2(velX, velY));
					});

					renderer.compute(precomputeShaderNode.compute(particleNum));
				};

				// use a compute shader to animate the point cloud's vertex data.

				const particleNode = attribute("particle", "vec2");

				const pointsGeometry = new THREE.BufferGeometry();
				pointsGeometry.setAttribute(
					"position",
					new THREE.BufferAttribute(new Float32Array(3), 3)
				); // single vertex ( not triangle )
				pointsGeometry.setAttribute("particle", particleBuffer); // dummy the position points as instances
				pointsGeometry.drawRange.count = 1; // force render points as instances ( not triangle )

				const pointsMaterial = new PointsNodeMaterial();
				pointsMaterial.colorNode = particleNode.add(color(0xffffff));
				pointsMaterial.positionNode = particleNode;

				const mesh = new THREE.Points(pointsGeometry, pointsMaterial);
				mesh.isInstancedMesh = true;
				mesh.count = particleNum;
				scene.add(mesh);

				renderer = new WebGPURenderer();
				renderer.setPixelRatio(window.devicePixelRatio);
				renderer.setSize(window.innerWidth, window.innerHeight);
				renderer.setAnimationLoop(animate);
				document.body.appendChild(renderer.domElement);

				window.addEventListener("resize", onWindowResize);
				window.addEventListener("mousemove", onMouseMove);

				// gui

				const gui = new GUI();

				gui.add(scaleVector, "x", 0, 1, 0.01);
				gui.add(scaleVector, "y", 0, 1, 0.01);
			}

			function onWindowResize() {
				camera.updateProjectionMatrix();
				renderer.setSize(window.innerWidth, window.innerHeight);
			}

			function onMouseMove(event) {
				const x = event.clientX;
				const y = event.clientY;

				const width = window.innerWidth;
				const height = window.innerHeight;

				pointerVector.set((x / width - 0.5) * 2.0, (-y / height + 0.5) * 2.0);
			}

			// function animate() {
			// 	renderer.compute(computeNode);
			// 	renderer.render(scene, camera);
			// }

			function animate() {
				// Update audio data
				analyser.getFrequencyData();

				// Update the audio data texture with the new frequency data
				audioDataTexture.value.image.data = new Uint8Array(analyser.data);

				// Dispatch compute shader
				renderer.compute(computeNode);

				// Render visualizer using render pipeline
				renderer.render(scene, camera);

				// Request next animation frame
				// requestAnimationFrame(animate);
			}
		</script>
	</body>
</html>
